{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "# **WEB SCRAPPING CON BeautifulSoup-Selenium**\n",
    "___________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Texto alternativo](ws1.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ficheros incluidos en la Página Web (URIs, URLs y URNs)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> *`URIs` --->   Uniform Resource Identifier o identificador de recursos uniforme) es un nombre, o formalmente una cadena de caracteres, que identifica un recurso de forma accesible dentro de una red: una página web, un fichero, etc. Su forma genérica es:\n",
    "\n",
    "        Schema:[//[user[:passwd]@]host[:port]][/path][?query][#tag]\n",
    "\n",
    "* (//[usuario[:passwd]@]host[:port]) ----> se la conoce como autoridad\n",
    "                    \n",
    "* ruta (path) ---> es una secuencia de nombres separadas  ya sea por los símbolos “/” o “:”\n",
    "\n",
    "* consulta (query) y una etiqueta (tag) ----> para acceder a un lugar concreto del documento\n",
    "\n",
    "Ejemplo: https://es.wikipedia.org/wiki/Alan_Turing#Turing_en_el_cine\n",
    "\n",
    "Por ejemplo https://www.youtube.com/watch?v=iSh9qg-2qKw. En este caso, la consulta se incluye con la forma v=codificaciónDeLaConsulta.\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">*`URLs` --->   s (Uniform Resource Locator o localizador de recurso uniforme), a menudo conocidas simplemente como direcciones web, sirven para especificar un recurso en la red mediante su localización y una forma o protocolo que permite recuperarlo, que corresponde con la parte schema de la estructura general de la URI. \n",
    "\n",
    "\n",
    "Además de esquemas o protocolos http o https, en ocasiones encontraremos URLs que especifican otros, como el File Transfer Protocol (FTP), por ejemplo en la siguiente URL:                 ftp://example.com.\n",
    "\n",
    ">*`URNs` --->  (Uniform Resource Name, o nombre de recurso uniforme), el otro tipo de URIs, identifica un recurso, pero no tienen por qué incluir ninguna forma de localizarlos. Un ejemplo puede ser urn:isbn:0-391-31341-0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo: datos de contaminación en Madrid\n",
    "\n",
    "    http://www.mambiente.munimadrid.es/opendata/horario.txt\n",
    "Esta URL proporciona los datos de las estaciones de medición de la calidad del aire\n",
    "de la ciudad de Madrid. Supongamos que queremos descargar el fichero\n",
    "correspondiente para analizarlo a continuación. Para ello, nos bastará con incluir la\n",
    "biblioteca requests que incluye un método para “pedir” (get) el fichero, que\n",
    "podemos grabar a continuación en nuestro disco duro local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "url = \"https://datos.madrid.es/egob/catalogo/218490-244-catalogo-datasets.txt\"\n",
    "resp = requests.get(url)\n",
    "print(resp) #Response 200 indica que se descargó con éxito en la URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distintos status_code, los que empiezan con 2 suelen indicar éxito, mientras que los que comienzan por 4 o 5 indican error, como el famosísimo 404 (recurso no encontrado) o el 403 (acceso prohibido al recurso)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Web_Scrapping_RafaelCaballero'\n",
    "with open (path + 'catalogo.txt', 'wb') as output: \n",
    "    output.write(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from contextlib import closing\n",
    "import csv\n",
    "import codecs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =  \"https://datos.madrid.es/egob/catalogo/218490-244-catalogo-datasets.txt\"\n",
    "with closing(requests.get(url, stream = True)) as r: \n",
    "    reader = csv.reader(codecs.iterdecode(\n",
    "                            r.iter_lines(),\n",
    "                            'utf-8'),\n",
    "                            delimiter=',')\n",
    "for row in reader: \n",
    "    print(row)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_csv.reader at 0x1ed9d24ff40>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FechaDescarga', 'idDataSet', 'Nombre', 'sector', 'Número de recursos', 'Descargas', 'Número de votos', 'formato_salida', 'frecuencia', '22/11/2018', 'F_ultima_act_metadatos', 'URL', 'FechaDescarga']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import chardet\n",
    "\n",
    "\n",
    "url = \"https://datos.madrid.es/egob/catalogo/218490-244-catalogo-datasets.txt\"\n",
    "\n",
    "\n",
    "local_filename = 'catalogo-datasets.txt'\n",
    "\n",
    "\n",
    "response = requests.get(url)\n",
    "with open(local_filename, 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "\n",
    "with open(local_filename, 'rb') as f:\n",
    "    raw_data = f.read()\n",
    "    result = chardet.detect(raw_data)\n",
    "    encoding = result['encoding']\n",
    "\n",
    "\n",
    "with open(local_filename, 'r', encoding=encoding) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter='\\t')  # Using tab delimiter as a guess\n",
    "    for row in reader:\n",
    "        print(row)\n",
    "        break  #Imprime solo la 1ra columna \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos que forman parte de la página \n",
    "\n",
    "Página web, que normalmente está compuesta por código HTML, imágenes,scripts y ficheros de estilo. \n",
    "\n",
    "Los datos que forman parte de la página pueden ser:\n",
    "\n",
    "* Indica que se trata de un documento HTML estándar de las páginas web -->  <``!DOCTYPE html``>\n",
    "\n",
    "* Etiqueta que marca el comienzo del documento, y que se cerrará al final\n",
    "del documento -->  <`/html`>  <`/html`>\n",
    "\n",
    "* , los elementos tienen una estructura con la forma:\n",
    "<`elemento atributo=\"valor\">Contenido</elemento`>\n",
    "\n",
    "* La cabecera del documento, como puede ser su título, el autor -->  <`head> … </head`>\n",
    "\n",
    "* Es el contenido en sí de la página, que es lo que nosotros deseamos examinar --> <`body> … </body`>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del elemento body habrá otros elementos, que dependerán de la página, que a su vez pueden contener otros elementos, y así sucesivamente. En nuestro pequeño ejemplo el cuerpo solo tiene dos frases, marcadas por las etiquetas <`div`> y <`/div`>. Podemos grabar este código en un fichero con el nombre que deseemos, por ejemplo mini.html. Haciendo doble clic sobre el fichero se abrirá el navegador y veremos la (humilde) página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from bs4 import BeautifulSoup\\nurl = r\"c:\\\\...\\\\mini.html\"\\nwith open(url, \"r\") as f:\\n    page = f.read()\\n    soup = BeautifulSoup(page, \"html.parser\")\\n    print(soup.prettify()) '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from bs4 import BeautifulSoup\n",
    "url = r\"c:\\...\\mini.html\"\n",
    "with open(url, \"r\") as f:\n",
    "    page = f.read()\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    print(soup.prettify()) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navegación absoluta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HTML siguen una estructura jerárquica. Los elementos que están directamente dentro de otros se dice que son hijos del elemento contenedor y hermanos entre sí. En nuestro miniejemplo, los elementos <`div id=\"date\"`> y <`div id=\"content\"`> son hermanos entre sí, y ambos son hijos del elemento `<body`>. Además, <`div id=\"date\"`> tiene a su vez un hijo, que en esta ocasión no es otro elemento sino un texto.\n",
    "\n",
    "\n",
    "La biblioteca BeautifulSoup nos permite utilizar estos conceptos para navegar por el documento buscando la información que precisamos. Como ejemplo inicial, podemos preguntar por los hijos del documento raíz, y su tipo para hacernos una idea de lo que vamos a encontrarnos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hijosDoc = list(soup.children)\\nprint([type(item) for item in hijosDoc])\\nprint(hijosDoc) '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" hijosDoc = list(soup.children)\n",
    "print([type(item) for item in hijosDoc])\n",
    "print(hijosDoc) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navegación relativa "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup ofrece la posibilidad de buscar elementos sin tener\n",
    "que explicar la ruta completa. Por ejemplo, el método find_all() busca todas las apariciones de un elemento a cualquier nivel y las devuelve en forma de lista:\n",
    "`divs = soup.find_all(\"div\")`\n",
    "\n",
    "Ahora, si sabemos que queremos mostrar el texto asociado al primer div\n",
    "podemos escribir:\n",
    "`print(divs[0].get_text())`\n",
    "\n",
    "Mediante el método find, devuelve directamente el primer objeto del\n",
    "documento que representa el elemento buscado:\n",
    "`print(soup.find(\"div\").get_text())`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo: día y hora oficiales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [404]>\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = \"https://www.boe.es/sede_electronica/informacion/hora_oficial.php\" \n",
    "r = requests.get(url)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 19:58:20 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): www.wikipedia.org:443\n",
      "2024-06-14 19:58:21 [urllib3.connectionpool] DEBUG: https://www.wikipedia.org:443 \"GET / HTTP/1.1\" 200 22499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English\n",
      "6,796,000+ articles\n",
      "\n",
      "English\n",
      "\n",
      "\n",
      "English\n",
      "6,796,000+ articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "日本語\n",
      "1,407,000+ 記事\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Español\n",
      "1.938.000+ artículos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Русский\n",
      "1 969 000+ статей\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Deutsch\n",
      "2.891.000+ Artikel\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Français\n",
      "2 598 000+ articles\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "中文\n",
      "1,409,000+ 条目 / 條目\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Italiano\n",
      "1.853.000+ voci\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "فارسی\n",
      "۹۹۵٬۰۰۰+ مقاله\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Português\n",
      "1.120.000+ artigos\n",
      "\n",
      "\n",
      "English\n",
      "日本語\n",
      "Español\n",
      "Русский\n",
      "Deutsch\n",
      "Français\n",
      "中文\n",
      "Italiano\n",
      "Português\n"
     ]
    }
   ],
   "source": [
    "import requests # pip install requests\n",
    "from lxml import html # pip install lxml\n",
    "\n",
    "# USER AGENT PARA PROTEGERNOS DE BANEOS\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "}\n",
    "\n",
    "# URL SEMILLA\n",
    "url = 'https://www.wikipedia.org/'\n",
    "\n",
    "# REQUERIMIENTO AL SERVIDOR\n",
    "respuesta = requests.get(url, headers=headers)\n",
    "respuesta.encoding = 'utf-8' # Codificar correctamente caracteres extranos\n",
    "\n",
    "# PARSEO DEL ARBOL HTML QUE RECIBO COMO RESPUESTA CON LXML\n",
    "parser = html.fromstring(respuesta.content) # Uso .content para poder codificar los caracteres raros\n",
    "\n",
    "# EXTRACCION DE IDIOMA INGLES\n",
    "ingles = parser.get_element_by_id(\"js-link-box-en\")\n",
    "print (ingles.text_content())\n",
    "\n",
    "# EXTRACCION SOLO DEL TEXTO QUE DICE INGLES\n",
    "ingles = parser.xpath(\"//a[@id='js-link-box-en']/strong/text()\")\n",
    "print(ingles[0])\n",
    "\n",
    "# EXTRACCION DE TODOS LOS IDIOMAS POR CLASE\n",
    "idiomas = parser.find_class('central-featured-lang')\n",
    "for idioma in idiomas:\n",
    "  print(idioma.text_content())\n",
    "\n",
    "# EXTRACCION DE TODOS LOS IDIOMAS POR XPATH\n",
    "idiomas = parser.xpath(\"//div[contains(@class,'central-featured-lang')]//strong/text()\")\n",
    "for idioma in idiomas:\n",
    "  print(idioma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 20:01:20 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): stackoverflow.com:443\n",
      "2024-06-14 20:01:21 [urllib3.connectionpool] DEBUG: https://stackoverflow.com:443 \"GET /questions HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stereoscopic video player web\n",
      "\n",
      "                I have an side by side video with right and left eye perspective in one single mp4 file. I want to be able to play it on an website. It should be shown in vr. The video should be splitted and rendered ...            \n",
      "\n",
      "\n",
      "Stereoscopic video player web\n",
      "\n",
      "                I have an side by side video with right and left eye perspective in one single mp4 file. I want to be able to play it on an website. It should be shown in vr. The video should be splitted and rendered ...            \n",
      "\n",
      "\n",
      "Which PCA results are correct?\n",
      "\n",
      "                I aim to find which directions in my data have \"vary greatly\". To do that, I understand a method called PCA, which uses the eigenvectors of the covariant matrix to find them.I used ...            \n",
      "\n",
      "\n",
      "Which PCA results are correct?\n",
      "\n",
      "                I aim to find which directions in my data have \"vary greatly\". To do that, I understand a method called PCA, which uses the eigenvectors of the covariant matrix to find them.I used ...            \n",
      "\n",
      "\n",
      "2018 world cup goals scored by country python dict\n",
      "\n",
      "                I have a .txt file with all goals scored in the 2018 world cup, there are 169 lines in this file structured as:playername;country;minute;EG:Gazinsky;Russia;12;Cheryshev;Russia;43;Cheryshev;Russia;...            \n",
      "\n",
      "\n",
      "2018 world cup goals scored by country python dict\n",
      "\n",
      "                I have a .txt file with all goals scored in the 2018 world cup, there are 169 lines in this file structured as:playername;country;minute;EG:Gazinsky;Russia;12;Cheryshev;Russia;43;Cheryshev;Russia;...            \n",
      "\n",
      "\n",
      "write a powershell script to start a few projects as \"start without debugging\" in VS2022\n",
      "\n",
      "                I would like to write a powershell script that start a given set of VS projects as if I run \"Start without debugging\" inside VS2022 for each of those projects. How may I do that?            \n",
      "\n",
      "\n",
      "write a powershell script to start a few projects as \"start without debugging\" in VS2022\n",
      "\n",
      "                I would like to write a powershell script that start a given set of VS projects as if I run \"Start without debugging\" inside VS2022 for each of those projects. How may I do that?            \n",
      "\n",
      "\n",
      "newrelic logging, does it affect existing logging?\n",
      "\n",
      "                Our java spring boot web app runs in AWS.  We want to use newrelic to monitor the api endpoints and their timings.  We dont want anything else, as we cant afford it.  AWS sends our logs to our self ...            \n",
      "\n",
      "\n",
      "newrelic logging, does it affect existing logging?\n",
      "\n",
      "                Our java spring boot web app runs in AWS.  We want to use newrelic to monitor the api endpoints and their timings.  We dont want anything else, as we cant afford it.  AWS sends our logs to our self ...            \n",
      "\n",
      "\n",
      "Bitbucket Server Branch Permissions API request gives wrong fields?\n",
      "\n",
      "                I am wanting to print out the branch permissions data to a CSV file, as seen in this screenshot,  by making a Bitbucket server API request. However, the data I am receiving does not map to the fields ...            \n",
      "\n",
      "\n",
      "Bitbucket Server Branch Permissions API request gives wrong fields?\n",
      "\n",
      "                I am wanting to print out the branch permissions data to a CSV file, as seen in this screenshot,  by making a Bitbucket server API request. However, the data I am receiving does not map to the fields ...            \n",
      "\n",
      "\n",
      "How do I get CDB to show source lines for Microsoft’s C++ Standard Library?\n",
      "\n",
      "                I’m working on contributing to Descent 3. The pull request that I’m currently working on has a Windows-only bug. I would like to use a debugger in order to help me track down the bug.Specifically, ...            \n",
      "\n",
      "\n",
      "How do I get CDB to show source lines for Microsoft’s C++ Standard Library?\n",
      "\n",
      "                I’m working on contributing to Descent 3. The pull request that I’m currently working on has a Windows-only bug. I would like to use a debugger in order to help me track down the bug.Specifically, ...            \n",
      "\n",
      "\n",
      "How to validate iOS purchases in 2024\n",
      "\n",
      "                It seems that the old \"verifyReceipt\" is deprecated. Apple tells me to magically verify the transaction on device. I don't understand how this works. I need to somehow verify a transaction ...            \n",
      "\n",
      "\n",
      "How to validate iOS purchases in 2024\n",
      "\n",
      "                It seems that the old \"verifyReceipt\" is deprecated. Apple tells me to magically verify the transaction on device. I don't understand how this works. I need to somehow verify a transaction ...            \n",
      "\n",
      "\n",
      "How to make a prompt to open different things with a batch file in DOSBox?\n",
      "\n",
      "                I've been making batch file shortcuts to my dos games in dosbox, and I want to make a batch file for doom 2 that asks you if you want to open doom 2, or open the setup file by typing either 1 or 2. ...            \n",
      "\n",
      "\n",
      "How to make a prompt to open different things with a batch file in DOSBox?\n",
      "\n",
      "                I've been making batch file shortcuts to my dos games in dosbox, and I want to make a batch file for doom 2 that asks you if you want to open doom 2, or open the setup file by typing either 1 or 2. ...            \n",
      "\n",
      "\n",
      "Mongodb database size is reduced after restore\n",
      "\n",
      "                I have two mongodb servers that I did a dump, transfer dump to second server and restored.Everything was done with no errors, but I see something (maybe) unusual for me.First server:admin> show ...            \n",
      "\n",
      "\n",
      "Mongodb database size is reduced after restore\n",
      "\n",
      "                I have two mongodb servers that I did a dump, transfer dump to second server and restored.Everything was done with no errors, but I see something (maybe) unusual for me.First server:admin> show ...            \n",
      "\n",
      "\n",
      "systemverilog testbench doesn't read txt file in quartus prime lite 20.1.1\n",
      "\n",
      "                I am a beginner. $readmemb doesn't read my TestBenchVector.txt file because the compiler gives error in reading underscores. On top of that ommiting them yields error in modelsimbeing impossible to ...            \n",
      "\n",
      "\n",
      "systemverilog testbench doesn't read txt file in quartus prime lite 20.1.1\n",
      "\n",
      "                I am a beginner. $readmemb doesn't read my TestBenchVector.txt file because the compiler gives error in reading underscores. On top of that ommiting them yields error in modelsimbeing impossible to ...            \n",
      "\n",
      "\n",
      "R help - advice on how to code results of qualtrics survey questions with randomized order choices\n",
      "\n",
      "                thanks in advance for your help.I'm cleaning data from a qualtrics survey that includes a few questions where the answer choices were randomized (e.g. you rate five tv shows, and the show order is ...            \n",
      "\n",
      "\n",
      "R help - advice on how to code results of qualtrics survey questions with randomized order choices\n",
      "\n",
      "                thanks in advance for your help.I'm cleaning data from a qualtrics survey that includes a few questions where the answer choices were randomized (e.g. you rate five tv shows, and the show order is ...            \n",
      "\n",
      "\n",
      "Why do I keep getting run time error 438, or 5 with this particular line\n",
      "\n",
      "                When I run this line of codeNewRbook.ActiveSheet.PivotTables(\"PTRegion\").ChangePivotCache (NewRbook.PivotCaches.Create(SourceType:=xlDatabase, SourceData:=\"TableTemp\"))I receive ...            \n",
      "\n",
      "\n",
      "Why do I keep getting run time error 438, or 5 with this particular line\n",
      "\n",
      "                When I run this line of codeNewRbook.ActiveSheet.PivotTables(\"PTRegion\").ChangePivotCache (NewRbook.PivotCaches.Create(SourceType:=xlDatabase, SourceData:=\"TableTemp\"))I receive ...            \n",
      "\n",
      "\n",
      "Performance issue when reading a single partition Kafka topic with Spark\n",
      "\n",
      "                There is a Kafka topic with a single partition, created to ensure the order of messages. However, when attempting to read one million messages per window in Spark Streaming, the process is ...            \n",
      "\n",
      "\n",
      "Performance issue when reading a single partition Kafka topic with Spark\n",
      "\n",
      "                There is a Kafka topic with a single partition, created to ensure the order of messages. However, when attempting to read one million messages per window in Spark Streaming, the process is ...            \n",
      "\n",
      "\n",
      "How can I make request to a Laravel route without refreshing the entire page?\n",
      "\n",
      "                I have this link in a specific section of the homepage. When clicking on this link, it calls the \"forbest\" route, which in turn calls the \"Home\" function from the controller. The ...            \n",
      "\n",
      "\n",
      "How can I make request to a Laravel route without refreshing the entire page?\n",
      "\n",
      "                I have this link in a specific section of the homepage. When clicking on this link, it calls the \"forbest\" route, which in turn calls the \"Home\" function from the controller. The ...            \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup # pip install beautifulsoup4\n",
    "\n",
    "# USER AGENT PARA PROTEGERNOS DE BANEOS\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# URL SEMILLA\n",
    "url = 'https://stackoverflow.com/questions'\n",
    "\n",
    "# REQUERIMIENTO AL SERVIDOR\n",
    "respuesta = requests.get(url, headers=headers)\n",
    "\n",
    "# PARSEO DEL ARBOL CON BEAUTIFUL SOUP\n",
    "soup = BeautifulSoup(respuesta.text)\n",
    "contenedor_de_preguntas = soup.find(id=\"questions\") # ENCONTRAR UN ELEMENTO POR ID\n",
    "lista_de_preguntas = contenedor_de_preguntas.find_all('div', class_=\"s-post-summary\") # ENCONTRAR VARIOS ELEMENTOS POR TAG Y POR CLASE\n",
    "for pregunta in lista_de_preguntas: # ITERAR ELEMENTO POR ELEMENTO\n",
    "\n",
    "  # METODO #1: METODO TRADICIONAL\n",
    "  texto_pregunta = pregunta.find('h3').text # DENTRO DE CADA ELEMENTO ITERADO ENCONTRAR UN TAG\n",
    "  descripcion_pregunta = pregunta.find(class_='s-post-summary--content-excerpt').text # ENCONTRAR POR CLASE\n",
    "  descripcion_pregunta = descripcion_pregunta.replace('\\n', '').replace('\\r', '') # LIMPIEZA DE TEXTO\n",
    "  print (texto_pregunta)\n",
    "  print (descripcion_pregunta)\n",
    "  print ()\n",
    "\n",
    "\n",
    "  # METODO #2: APROVECHANDO EL PODER COMPLETO DE BEAUTIFUL SOUP\n",
    "  contenedor_pregunta = pregunta.find('h3')\n",
    "  texto_pregunta = contenedor_pregunta.text\n",
    "  descripcion_pregunta = contenedor_pregunta.find_next_sibling('div') # TRAVERSANDO EL ARBOL DE UNA MENERA DIFERENTE\n",
    "  texto_descripcion_pregunta = descripcion_pregunta.text\n",
    "\n",
    "  texto_descripcion_pregunta = texto_descripcion_pregunta.replace('\\n', '').replace('\\t', '')\n",
    "  print (texto_pregunta)\n",
    "  print (texto_descripcion_pregunta)\n",
    "  print ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Curso_Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
